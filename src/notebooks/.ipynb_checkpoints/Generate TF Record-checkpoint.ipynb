{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837b2c34",
   "metadata": {},
   "source": [
    "# Notebook for Generating TensorFlow Records for Dataset\n",
    "A record allows for serialized, structured data to be represented in a binary format and cross-platform. \n",
    "This allows models to be easily re-trained on platform independent data, and stored in a compiled format.\n",
    "\n",
    "To prepare such a record, a few things are needed:\n",
    "1. A collection of CSV records for the training of the model, including the labels, classifications, and file names\n",
    "2. The image files themselves.\n",
    "\n",
    "Credit is due to the TensorFlow team for providing a utility for this, modified below.\n",
    "\n",
    "[Official TFRecord Reference](https://www.tensorflow.org/tutorials/load_data/tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432b75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.framework.versions import VERSION\n",
    "if VERSION >= \"2.0.0a0\":\n",
    "    import tensorflow.compat.v1 as tf\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9aa95d",
   "metadata": {},
   "source": [
    "The variables below can be configured depending on the needs and locations of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b7fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_input = \"../data/train_labels.csv\"\n",
    "image_dir = \"../data/images\"\n",
    "output_path = \"train.record\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc27797",
   "metadata": {},
   "source": [
    "The function below allows for conversion between the textual naming identity of the classifications and\n",
    "the integer representations. This is how the classifications are stored internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b863e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'military tank':\n",
    "        return 1\n",
    "    elif row_label == 'military aircraft':\n",
    "        return 2\n",
    "    elif row_label == 'military truck':\n",
    "        return 3\n",
    "    elif row_label == 'civilian aircraft':\n",
    "        return 4\n",
    "    elif row_label == 'civilian car':\n",
    "        return 5\n",
    "    elif row_label == 'military helicopter':\n",
    "        return 6\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a02a8",
   "metadata": {},
   "source": [
    "The next step is to create the binary representation of the record and return it. This is formatted to allow TF to train on this data. This is done by first reading in the file as raw JPG data, setting all of the attributes in the binary format, and returning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f36a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    # Add all of the objects to the arrays.\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "        \n",
    "    tf_record = tf.train.Example(features=tf.train.Features(feature = {\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes)\n",
    "    }))\n",
    "\n",
    "    return tf_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82923946",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m writer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFRecordWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), image_dir)\n\u001b[1;32m      3\u001b[0m examples \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_input)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/lib/io/tf_record.py:294\u001b[0m, in \u001b[0;36mTFRecordWriter.__init__\u001b[0;34m(self, path, options)\u001b[0m\n\u001b[1;32m    291\u001b[0m   options \u001b[38;5;241m=\u001b[39m TFRecordOptions(compression_type\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFRecordWriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_record_writer_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ; No such file or directory"
     ]
    }
   ],
   "source": [
    "writer = tf.python_io.TFRecordWriter(output_path)\n",
    "path = os.path.join(os.getcwd(), image_dir)\n",
    "examples = pd.read_csv(csv_input)\n",
    "grouped = split(examples, 'filename')\n",
    "\n",
    "for group in grouped:\n",
    "    tf_record = create_tf_record(group, path)\n",
    "    writer.write(tf_record.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "output_path = os.path.join(os.getcwd(), output_path)\n",
    "print(f\"Successfully created the TFRecords: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
