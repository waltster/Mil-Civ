{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b019ec3",
   "metadata": {},
   "source": [
    "# Notebook for Training Model\n",
    "This notebook contains all of the commands, environment setup, and code to begin training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f471d",
   "metadata": {},
   "source": [
    "# 1. Downloading and Building Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tensorflow/models.git ../model/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../model/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ecfa0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!copy object_detection/packages/tf2/setup.py ./\n",
    "!python -m pip install .\n",
    "!python object_detection/builders/model_builder_tf2_test.py\n",
    "%cd ../../../notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962345e5",
   "metadata": {},
   "source": [
    "# 2. Generating TensorFlow Records for Data\n",
    "Generating TF Records is an important step in generating the model as a whole.\n",
    "This component allows TF to parse and train the model and for the distribution\n",
    "of the model in a cross-platform format. See `src/notebooks/Generate TF Record` \n",
    "notebook for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_input = \"../data/train_labels.csv\"\n",
    "test_csv_input = \"../data/test_labels.csv\"\n",
    "train_output_path = \"../model/train.record\"\n",
    "test_output_path = \"../model/test.record\"\n",
    "image_dir = \"../data/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e83d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.framework.versions import VERSION\n",
    "if VERSION >= \"2.0.0a0\":\n",
    "    import tensorflow.compat.v1 as tf\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'military tank':\n",
    "        return 1\n",
    "    elif row_label == 'military aircraft':\n",
    "        return 2\n",
    "    elif row_label == 'military truck':\n",
    "        return 3\n",
    "    elif row_label == 'civilian aircraft':\n",
    "        return 4\n",
    "    elif row_label == 'civilian car':\n",
    "        return 5\n",
    "    elif row_label == 'military helicopter':\n",
    "        return 6\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_record(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    # Add all of the objects to the arrays.\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "        \n",
    "    tf_record = tf.train.Example(features=tf.train.Features(feature = {\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes)\n",
    "    }))\n",
    "    \n",
    "    return tf_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e27776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(csv_input, output_path):\n",
    "    global image_dir\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    path = os.path.join(os.getcwd(), image_dir)\n",
    "\n",
    "    print(\"Reading CSV label file...\")\n",
    "    examples = pd.read_csv(csv_input)\n",
    "    grouped = split(examples, 'filename')\n",
    "\n",
    "    print(\"Beginning compilation...\")\n",
    "\n",
    "    for group in grouped:\n",
    "        tf_record = create_tf_record(group, path)\n",
    "        writer.write(tf_record.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    output_path = os.path.join(os.getcwd(), output_path)\n",
    "    print(f\"Successfully created the TFRecords: \\n{output_path}\")\n",
    "\n",
    "create_record(train_csv_input, train_output_path)\n",
    "create_record(test_csv_input, test_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc0de1",
   "metadata": {},
   "source": [
    "# 3. Downloading Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ../model/content\n",
    "%cd ../model/content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c4f98",
   "metadata": {},
   "source": [
    "First, the model itelf must be downloaded. This model is specifically used for object detection and classification, though outhers are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/classification/tf2/20200710/mobilenet_v2.tar.gz\n",
    "!tar -xvf mobilenet_v2.tar.gz\n",
    "!rm mobilenet_v2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e804a05",
   "metadata": {},
   "source": [
    "Next, the configuration must be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a698090",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
    "!mv ssd_mobilenet_v2_320x320_coco17_tpu-8.config mobilenet_v2.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e824a",
   "metadata": {},
   "source": [
    "TensorFlow has provided a simple [script](https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html) automatically adjusting the configuration, employed below. These values can be tweaked and adjusted for more accurate/longer training times, or for expirementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87831004",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "batch_size = 4\n",
    "num_steps = 7500\n",
    "num_eval_steps = 1000\n",
    "\n",
    "train_record_path = \"../train.record\"\n",
    "test_record_path = \"../test.record\"\n",
    "model_dir = \"../training\"\n",
    "labelmap_path = \"labelmap.pbtxt\"\n",
    "pipeline_config_path = \"mobilenet_v2.config\"\n",
    "fine_tune_checkpoint = \"mobilenet_v2/mobilenet_v2.ckpt-1\"\n",
    "\n",
    "import re\n",
    "\n",
    "with open(pipeline_config_path) as f:\n",
    "    config = f.read()\n",
    "\n",
    "with open(pipeline_config_path, 'w') as f:\n",
    "    config = re.sub('label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
    "\n",
    "    config = re.sub(\n",
    "        'fine_tune_checkpoint: \".*?\"', \n",
    "        'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), \n",
    "        config\n",
    "    )\n",
    "    \n",
    "    config = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")',\n",
    "        'input_path: \"{}\"'.format(test_record_path), config\n",
    "    )\n",
    "    \n",
    "    config = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")',\n",
    "        'input_path: \"{}\"'.format(test_record_path), config\n",
    "    )\n",
    "    \n",
    "    config = re.sub(\n",
    "        'num_classes: [0-9]+',\n",
    "        'num_classes: {}'.format(6), config\n",
    "    )\n",
    "    \n",
    "    config = re.sub(\n",
    "        'batch_size: [0-9]+',\n",
    "        'batch_size: {}'.format(batch_size, config\n",
    ")    )\n",
    "    \n",
    "    config = re.sub(\n",
    "        'num_steps: [0-9]+',\n",
    "        'num_steps: {}'.format(num_steps), config\n",
    "    )\n",
    "    \n",
    "    f.write(config)\n",
    "    print('Finished writing configuration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d6c09",
   "metadata": {},
   "source": [
    "# 4. Start Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 uninstall numpy -y\n",
    "!pip3 install numpy\n",
    "%cd ..\n",
    "!python3 models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path=content/{pipeline_config_path} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec798f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wpach/Dropbox/School/USC/Fall 2022/CSCE-585/Project/src/model\n"
     ]
    }
   ],
   "source": [
    "cd ../model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea6941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wpach/Dropbox/School/USC/Fall 2022/CSCE-585/Project/src/model\n",
      "events.out.tfevents.1663877095.Walters-MBP.attlocal.net.14463.0.v2\n",
      "events.out.tfevents.1663877244.Walters-MBP.attlocal.net.14480.0.v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-547026c33299acf8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-547026c33299acf8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pwd\n",
    "%reload_ext tensorboard\n",
    "%ls training/train\n",
    "%tensorboard --logdir=training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abce4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 14618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adb6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
